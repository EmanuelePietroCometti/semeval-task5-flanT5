{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97e4d0cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e4d0cd",
        "outputId": "0741fdff-34a3-4ee6-bd74-aa43e112d004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 193 (delta 116), reused 129 (delta 54), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (193/193), 43.33 KiB | 10.83 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/EmanuelePietroCometti/semeval-task5-flanT5.git code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "921579c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "921579c6",
        "outputId": "439fd543-bc14-4af3-91ec-e6dcfe04fe16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ZwPh2h26JtPM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwPh2h26JtPM",
        "outputId": "af4da753-24b1-49ef-c4df-9800cf238b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/code\n"
          ]
        }
      ],
      "source": [
        "%cd code/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b11294b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b11294b9",
        "outputId": "5be10196-680f-4fdf-869e-01d8a8fc5e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dati copiati da Drive!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs(\"data/raw\", exist_ok=True)\n",
        "\n",
        "source_dir = \"/content/drive/MyDrive/LLM - Progetto/data\"\n",
        "shutil.copy(f\"{source_dir}/train.json\", \"data/raw/train.json\")\n",
        "shutil.copy(f\"{source_dir}/dev.json\", \"data/raw/dev.json\")\n",
        "shutil.copy(f\"{source_dir}/test.json\", \"data/raw/test.json\")\n",
        "print(\"Dati copiati da Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Bkf5YpYaJ8g6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkf5YpYaJ8g6",
        "outputId": "939bed16-aeda-4d3e-bdff-81ed4fb7073a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\tpyproject.toml\t  scripts\t src\n",
            "launcher.ipynb\trequirements.txt  setup_repo.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2M086BjeJ33I",
      "metadata": {
        "id": "2M086BjeJ33I"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "XR8E1KlcSHSV",
      "metadata": {
        "id": "XR8E1KlcSHSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7f5380-0020-4234-e732-1c62970137c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms346291\u001b[0m (\u001b[33ms346291-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "try:\n",
        "  os.environ[\"WANDB_API_KEY\"] = userdata.get('wandb_api_key')\n",
        "  wandb.login(key=userdata.get('wandb_api_key'), relogin=True)\n",
        "  if wandb.run is not None:\n",
        "          wandb.finish()\n",
        "except Exception as e:\n",
        "    print(f\"Errore nel login di W&B: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "si-gY_z8AHR3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si-gY_z8AHR3",
        "outputId": "c8ba1198-7255-4dd4-9110-0df0f2d40c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769683560.556086    1261 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769683560.562792    1261 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769683560.579434    1261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769683560.579474    1261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769683560.579478    1261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769683560.579481    1261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading model: google/flan-t5-large...\n",
            "tokenizer_config.json: 2.54kB [00:00, 13.3MB/s]\n",
            "spiece.model: 100% 792k/792k [00:01<00:00, 657kB/s]\n",
            "tokenizer.json: 2.42MB [00:00, 143MB/s]\n",
            "special_tokens_map.json: 2.20kB [00:00, 14.4MB/s]\n",
            "config.json: 100% 662/662 [00:00<00:00, 4.04MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 3.13G/3.13G [00:07<00:00, 398MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 1.03MB/s]\n",
            "Applying LoRA config...\n",
            "trainable params: 14,096,384 || all params: 797,246,464 || trainable%: 1.7681\n",
            "Tokenizing datasets...\n",
            "Map: 100% 2280/2280 [00:00<00:00, 3513.26 examples/s]\n",
            "Map: 100% 588/588 [00:00<00:00, 3545.49 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "DefaultFlowCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "EvaluationLogCallback\n",
            "ProgressCallback\n",
            "PrinterCallback presente: False\n",
            "-- Avvio Training --\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms346291\u001b[0m (\u001b[33ms346291-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run gmfxlhyo (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run gmfxlhyo (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run gmfxlhyo (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.24.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/code/wandb/run-20260129_104627-gmfxlhyo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcopper-meadow-77\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface/runs/gmfxlhyo\u001b[0m\n",
            "\n",
            "Step     | Train Loss   | Eval Loss    | Acc        | Spearman   | Combined  \n",
            "-----------------------------------------------------------------------------\n",
            "100      | 1.2524       | 0.7914       | 0.6156     | 0.3091     | 0.5237    \n",
            "200      | 1.6949       | 0.7702       | 0.6429     | 0.3649     | 0.5595    \n",
            "300      | 1.5350       | 0.7602       | 0.6582     | 0.4088     | 0.5833    \n",
            "400      | 1.4224       | 0.8389       | 0.6667     | 0.4478     | 0.6010    \n",
            "500      | 1.3818       | 0.7675       | 0.6956     | 0.4666     | 0.6269    \n",
            "600      | 0.9612       | 0.7936       | 0.7398     | 0.4973     | 0.6670    \n",
            "700      | 1.0435       | 0.7928       | 0.7109     | 0.5028     | 0.6484    \n",
            "800      | 0.8635       | 0.8335       | 0.7177     | 0.5168     | 0.6574    \n",
            "900      | 0.8326       | 0.8385       | 0.7058     | 0.5377     | 0.6553    \n",
            "1000     | 0.6786       | 0.8421       | 0.7245     | 0.5561     | 0.6740    \n",
            "1100     | 0.8196       | 0.8314       | 0.7211     | 0.5737     | 0.6769    \n",
            "1200     | 0.5274       | 0.9003       | 0.7143     | 0.5578     | 0.6673    \n",
            "1300     | 0.6717       | 0.8995       | 0.7092     | 0.5648     | 0.6659    \n",
            "1400     | 0.7147       | 0.9001       | 0.7211     | 0.5697     | 0.6757    \n",
            "1500     | 0.5540       | 0.8751       | 0.7177     | 0.5754     | 0.6750    \n",
            "1600     | 0.5515       | 0.9182       | 0.7160     | 0.5815     | 0.6757    \n",
            "-- Avvio Evaluation --\n",
            "1600     | 0.5515       | 0.8314       | 0.7211     | 0.5737     | 0.6769    \n",
            "Accuracy within std: 0.7210884353741497\n",
            "Spearman: 0.5737090524525622\n",
            "Model saved to outputs/models/flan_t5_lora_v1\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33mcopper-meadow-77\u001b[0m at: \u001b[34mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface/runs/gmfxlhyo\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260129_104627-gmfxlhyo/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -u scripts/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "IKOWLDxVAPAD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKOWLDxVAPAD",
        "outputId": "075f4d95-dcfb-47c7-d106-23ac5c91ed95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coping model to /content/drive/MyDrive/LLM - Progetto/modelli salvati/versioni/flan-T5-EncDec/flan_lora_20260129_1125...\n",
            "Backup completato! Ora sei al sicuro.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import datetime\n",
        "\n",
        "dest_folder = f\"/content/drive/MyDrive/LLM - Progetto/modelli salvati/versioni/flan-T5-EncDec/flan_lora_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "\n",
        "print(f\"Coping model to {dest_folder}...\")\n",
        "shutil.copytree(\"outputs/models/flan_t5_lora_v1\", dest_folder)\n",
        "print(\"Backup completato! Ora sei al sicuro.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "VvSvPJsLDWh1",
      "metadata": {
        "id": "VvSvPJsLDWh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e55ef11-1e95-4e01-8f0f-d4c4ccc234ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 11:25:43.994288: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-29 11:25:44.012028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769685944.033393   11479 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769685944.039876   11479 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769685944.056624   11479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769685944.056659   11479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769685944.056662   11479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769685944.056665   11479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-29 11:25:44.061554: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading base model: google/flan-t5-large...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading LoRA adapters from: outputs/models/flan_t5_lora_v1...\n",
            "Leggo i dati da data/raw/test.json...\n",
            "Avvio inferenza su 930 esempi...\n",
            "Predizioni salvate in: outputs/predictions/predictions.jsonl\n",
            "Creo archivio ZIP...\n",
            "Tutto pronto! File da sottomettere: outputs/predictions/predictions.zip\n"
          ]
        }
      ],
      "source": [
        "!python scripts/predict.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "folders_to_zip = [\n",
        "    \"/content/code/outputs/models/flan_t5_lora_v1\"\n",
        "]\n",
        "\n",
        "for folder_path in folders_to_zip:\n",
        "    if os.path.exists(folder_path):\n",
        "        zip_filename = folder_path.split('/')[-1]\n",
        "\n",
        "        print(f\"Creazione archivio per: {folder_path}...\")\n",
        "        shutil.make_archive(zip_filename, 'zip', folder_path)\n",
        "    else:\n",
        "        print(f\"ERRORE: La cartella {folder_path} non esiste. Controlla il percorso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjz1tbExgdZb",
        "outputId": "05065005-f6bf-4eb5-a201-14fc386da3b3"
      },
      "id": "Yjz1tbExgdZb",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creazione archivio per: /content/code/outputs/models/flan_t5_lora_v1...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}