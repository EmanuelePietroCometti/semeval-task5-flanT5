{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97e4d0cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e4d0cd",
        "outputId": "6bb9c93c-bbdd-49d0-a556-5ca94e1c630f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 104 (delta 54), reused 80 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (104/104), 25.23 KiB | 12.62 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/EmanuelePietroCometti/semeval-task5-flanT5.git code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "921579c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "921579c6",
        "outputId": "df30905d-7b47-4177-9b54-9da4661b7729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ZwPh2h26JtPM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwPh2h26JtPM",
        "outputId": "cf59b792-bbfb-45d4-907a-088be2e584ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/code\n"
          ]
        }
      ],
      "source": [
        "%cd code/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b11294b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b11294b9",
        "outputId": "3346d285-2041-4f82-9960-22042ea6e25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dati copiati da Drive!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs(\"data/raw\", exist_ok=True)\n",
        "\n",
        "source_dir = \"/content/drive/MyDrive/LLM - Progetto/data\"\n",
        "shutil.copy(f\"{source_dir}/train.json\", \"data/raw/train.json\")\n",
        "shutil.copy(f\"{source_dir}/dev.json\", \"data/raw/dev.json\")\n",
        "shutil.copy(f\"{source_dir}/test.json\", \"data/raw/test.json\")\n",
        "print(\"Dati copiati da Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Bkf5YpYaJ8g6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkf5YpYaJ8g6",
        "outputId": "8551219b-5de4-4f61-c6e4-faf9581af5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\tpyproject.toml\t  scripts\t src\n",
            "launcher.ipynb\trequirements.txt  setup_repo.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2M086BjeJ33I",
      "metadata": {
        "id": "2M086BjeJ33I"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "XR8E1KlcSHSV",
      "metadata": {
        "id": "XR8E1KlcSHSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f8cc01-c756-4269-c708-a5a986ddc9d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms346291\u001b[0m (\u001b[33ms346291-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "try:\n",
        "  os.environ[\"WANDB_API_KEY\"] = userdata.get('wandb_api_key')\n",
        "  wandb.login(key=userdata.get('wandb_api_key'), relogin=True)\n",
        "  if wandb.run is not None:\n",
        "          wandb.finish()\n",
        "except Exception as e:\n",
        "    print(f\"Errore nel login di W&B: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "si-gY_z8AHR3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si-gY_z8AHR3",
        "outputId": "7791b142-8bd4-49bb-8526-de83c54765da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769525441.194042     897 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769525441.200787     897 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769525441.218150     897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769525441.218204     897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769525441.218207     897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769525441.218210     897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading model: google/flan-t5-large...\n",
            "tokenizer_config.json: 2.54kB [00:00, 10.1MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 1.23MB/s]\n",
            "tokenizer.json: 2.42MB [00:00, 20.5MB/s]\n",
            "special_tokens_map.json: 2.20kB [00:00, 11.8MB/s]\n",
            "config.json: 100% 662/662 [00:00<00:00, 5.61MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 3.13G/3.13G [00:12<00:00, 246MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 965kB/s]\n",
            "Applying LoRA config...\n",
            "trainable params: 14,096,384 || all params: 797,246,464 || trainable%: 1.7681\n",
            "Tokenizing datasets...\n",
            "Map: 100% 2280/2280 [00:00<00:00, 3217.01 examples/s]\n",
            "Map: 100% 588/588 [00:00<00:00, 3159.02 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "DefaultFlowCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "EvaluationLogCallback\n",
            "ProgressCallback\n",
            "PrinterCallback presente: False\n",
            "-- Avvio Training --\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms346291\u001b[0m (\u001b[33ms346291-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.24.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/code/wandb/run-20260127_145111-i9t19q75\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-darkness-65\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface/runs/i9t19q75\u001b[0m\n",
            "\n",
            "Step     | Train Loss   | Eval Loss    | Acc        | Spearman   | Combined  \n",
            "-----------------------------------------------------------------------------\n",
            "100      | 1.0446       | 0.8703       | 0.5663     | 0.2351     | 0.4670    \n",
            "200      | 1.1529       | 0.8029       | 0.6224     | 0.3305     | 0.5349    \n",
            "300      | 1.0620       | 0.7718       | 0.6122     | 0.3792     | 0.5423    \n",
            "400      | 0.9655       | 0.7576       | 0.6820     | 0.4787     | 0.6210    \n",
            "500      | 0.9966       | 0.7270       | 0.7143     | 0.5419     | 0.6626    \n",
            "600      | 0.9425       | 0.7156       | 0.7449     | 0.5857     | 0.6972    \n",
            "700      | 0.7867       | 0.7199       | 0.7347     | 0.5888     | 0.6909    \n",
            "800      | 0.8122       | 0.7078       | 0.7364     | 0.6030     | 0.6964    \n",
            "900      | 0.6132       | 0.7249       | 0.7534     | 0.6064     | 0.7093    \n",
            "1000     | 0.6063       | 0.7193       | 0.7568     | 0.6092     | 0.7125    \n",
            "1100     | 0.6905       | 0.7233       | 0.7449     | 0.6022     | 0.7021    \n",
            "1200     | 0.5512       | 0.7417       | 0.7500     | 0.6034     | 0.7060    \n",
            "1300     | 0.6107       | 0.7255       | 0.7551     | 0.6123     | 0.7123    \n",
            "1400     | 0.6707       | 0.7336       | 0.7619     | 0.6099     | 0.7163    \n",
            "1500     | 0.6295       | 0.7351       | 0.7483     | 0.6075     | 0.7060    \n",
            "1600     | 0.6718       | 0.7493       | 0.7585     | 0.6083     | 0.7135    \n",
            "1700     | 0.6282       | 0.7473       | 0.7534     | 0.6138     | 0.7115    \n",
            "1800     | 0.5105       | 0.7404       | 0.7636     | 0.6141     | 0.7187    \n",
            "1900     | 0.6182       | 0.7409       | 0.7670     | 0.6150     | 0.7214    \n",
            "2000     | 0.5682       | 0.7428       | 0.7636     | 0.6144     | 0.7188    \n",
            "2100     | 0.5414       | 0.7498       | 0.7551     | 0.6116     | 0.7121    \n",
            "2200     | 0.5550       | 0.7500       | 0.7551     | 0.6110     | 0.7119    \n",
            "2300     | 0.4999       | 0.7486       | 0.7585     | 0.6125     | 0.7147    \n",
            "-- Avvio Evaluation --\n",
            "2300     | 0.4999       | 0.7409       | 0.7670     | 0.6150     | 0.7214    \n",
            "Accuracy within std: 0.7670068027210885\n",
            "Spearman: 0.6149689264814713\n",
            "Model saved to outputs/models/flan_t5_lora_v1\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33msilver-darkness-65\u001b[0m at: \u001b[34mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface/runs/i9t19q75\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260127_145111-i9t19q75/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -u scripts/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "IKOWLDxVAPAD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKOWLDxVAPAD",
        "outputId": "08f491fb-0fd4-4db0-f432-beac0c70673b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coping model to /content/drive/MyDrive/LLM - Progetto/modelli salvati/versioni/flan-T5-EncDec/flan_lora_20260127_1547...\n",
            "Backup completato! Ora sei al sicuro.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import datetime\n",
        "\n",
        "dest_folder = f\"/content/drive/MyDrive/LLM - Progetto/modelli salvati/versioni/flan-T5-EncDec/flan_lora_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "\n",
        "print(f\"Coping model to {dest_folder}...\")\n",
        "shutil.copytree(\"outputs/models/flan_t5_lora_v1\", dest_folder)\n",
        "print(\"Backup completato! Ora sei al sicuro.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "id": "Q83cQK-VLSwm",
        "outputId": "bfb61875-e5ef-48eb-fad6-818325ba1278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Q83cQK-VLSwm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 413 bytes | 413.00 KiB/s, done.\n",
            "From https://github.com/EmanuelePietroCometti/semeval-task5-flanT5\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   3ca178c..50c11b2  main       -> origin/main\n",
            "Updating 3ca178c..50c11b2\n",
            "Fast-forward\n",
            " scripts/predict.py | 7 \u001b[32m+++\u001b[m\u001b[31m----\u001b[m\n",
            " 1 file changed, 3 insertions(+), 4 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "VvSvPJsLDWh1",
      "metadata": {
        "id": "VvSvPJsLDWh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "51f4f463-5b81-4ff0-81df-9cd50b239903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-27 15:58:26.772007: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-27 15:58:26.790223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769529506.812826   18455 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769529506.819433   18455 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769529506.836575   18455 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769529506.836619   18455 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769529506.836622   18455 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769529506.836625   18455 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-27 15:58:26.841627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading base model: google/flan-t5-large...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading LoRA adapters from: outputs/models/flan_t5_lora_v1...\n",
            "Leggo i dati da data/raw/test.json...\n",
            "Avvio inferenza su 930 esempi...\n",
            "Predizioni salvate in: outputs/predictions/predictions.jsonl\n",
            "Creo archivio ZIP...\n",
            "Tutto pronto! File da sottomettere: outputs/predictions/predictions.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eefcd438-2000-48d1-a475-b9727320f2a3\", \"predictions.zip\", 11990)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!python scripts/predict.py\n",
        "\n",
        "from google.colab import files\n",
        "if os.path.exists(\"outputs/predictions/predictions.zip\"):\n",
        "    files.download(\"outputs/predictions/predictions.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "folders_to_download = [\n",
        "    \"/content/code/outputs/models/flan-t5-lora\",\n",
        "    \"/content/code/outputs/models/flan-t5-lora-v1\"\n",
        "]\n",
        "\n",
        "for folder_path in folders_to_download:\n",
        "    if os.path.exists(folder_path):\n",
        "        zip_filename = folder_path.split('/')[-1]\n",
        "\n",
        "        print(f\"Creazione archivio per: {folder_path}...\")\n",
        "        shutil.make_archive(zip_filename, 'zip', folder_path)\n",
        "\n",
        "        print(f\"Avvio download di: {zip_filename}.zip\")\n",
        "        files.download(f\"{zip_filename}.zip\")\n",
        "    else:\n",
        "        print(f\"ERRORE: La cartella {folder_path} non esiste. Controlla il percorso.\")"
      ],
      "metadata": {
        "id": "8BGjVtnyNEx1"
      },
      "id": "8BGjVtnyNEx1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}