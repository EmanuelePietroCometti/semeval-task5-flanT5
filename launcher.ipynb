{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97e4d0cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e4d0cd",
        "outputId": "eb8257a2-701d-4092-adbb-36e79cf9c0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 154 (delta 87), reused 104 (delta 39), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (154/154), 37.49 KiB | 1.63 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/EmanuelePietroCometti/semeval-task5-flanT5.git code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "921579c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "921579c6",
        "outputId": "f6c8427e-c0ca-4b8d-a76e-42dbd2bbc83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ZwPh2h26JtPM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwPh2h26JtPM",
        "outputId": "154d2425-79e1-4904-e1e8-94b617833107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/code\n"
          ]
        }
      ],
      "source": [
        "%cd code/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b11294b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b11294b9",
        "outputId": "1f7d42ad-3f35-4291-8975-4baa9a34d354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dati copiati da Drive!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs(\"data/raw\", exist_ok=True)\n",
        "\n",
        "source_dir = \"/content/drive/MyDrive/LLM - Progetto/data\"\n",
        "shutil.copy(f\"{source_dir}/train.json\", \"data/raw/train.json\")\n",
        "shutil.copy(f\"{source_dir}/dev.json\", \"data/raw/dev.json\")\n",
        "shutil.copy(f\"{source_dir}/test.json\", \"data/raw/test.json\")\n",
        "print(\"Dati copiati da Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Bkf5YpYaJ8g6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkf5YpYaJ8g6",
        "outputId": "e30832f8-8128-4f2c-a80f-0dbd74bcd6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\tpyproject.toml\t  scripts\t src\n",
            "launcher.ipynb\trequirements.txt  setup_repo.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2M086BjeJ33I",
      "metadata": {
        "id": "2M086BjeJ33I"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "XR8E1KlcSHSV",
      "metadata": {
        "id": "XR8E1KlcSHSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39dcd892-288d-4271-b0ea-4998529d8565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms346291\u001b[0m (\u001b[33ms346291-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "try:\n",
        "  os.environ[\"WANDB_API_KEY\"] = userdata.get('wandb_api_key')\n",
        "  wandb.login(key=userdata.get('wandb_api_key'), relogin=True)\n",
        "  if wandb.run is not None:\n",
        "          wandb.finish()\n",
        "except Exception as e:\n",
        "    print(f\"Errore nel login di W&B: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "si-gY_z8AHR3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si-gY_z8AHR3",
        "outputId": "c234321d-c014-4dfc-913c-9770a9d427de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769616915.019696    1121 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769616915.026104    1121 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769616915.042813    1121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769616915.042857    1121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769616915.042860    1121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769616915.042862    1121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading model: google/flan-t5-large...\n",
            "tokenizer_config.json: 2.54kB [00:00, 12.6MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 1.35MB/s]\n",
            "tokenizer.json: 2.42MB [00:00, 52.5MB/s]\n",
            "special_tokens_map.json: 2.20kB [00:00, 14.7MB/s]\n",
            "config.json: 100% 662/662 [00:00<00:00, 7.59MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 3.13G/3.13G [00:09<00:00, 347MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 1.27MB/s]\n",
            "Applying LoRA config...\n",
            "trainable params: 14,096,384 || all params: 797,246,464 || trainable%: 1.7681\n",
            "Tokenizing datasets...\n",
            "Map: 100% 2280/2280 [00:00<00:00, 3338.54 examples/s]\n",
            "Map: 100% 588/588 [00:00<00:00, 3525.60 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "DefaultFlowCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "EvaluationLogCallback\n",
            "ProgressCallback\n",
            "PrinterCallback presente: False\n",
            "-- Avvio Training --\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms346291\u001b[0m (\u001b[33ms346291-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.24.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/code/wandb/run-20260128_161538-8ket5q1o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myoung-serenity-70\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface/runs/8ket5q1o\u001b[0m\n",
            "\n",
            "Step     | Train Loss   | Eval Loss    | Acc        | Spearman   | Combined  \n",
            "-----------------------------------------------------------------------------\n",
            "100      | 2.8151       | 0.8643       | 0.5748     | 0.1814     | 0.4568    \n",
            "200      | 4.1837       | 0.8299       | 0.6344     | 0.2820     | 0.5286    \n",
            "300      | 3.4661       | 0.8244       | 0.6259     | 0.3254     | 0.5357    \n",
            "400      | 3.8109       | 0.8496       | 0.6888     | 0.4487     | 0.6167    \n",
            "500      | 3.5001       | 0.8142       | 0.6922     | 0.5007     | 0.6347    \n",
            "600      | 2.2535       | 0.8101       | 0.7415     | 0.5488     | 0.6837    \n",
            "700      | 2.3027       | 0.8662       | 0.6786     | 0.5338     | 0.6351    \n",
            "800      | 1.8362       | 0.8167       | 0.7262     | 0.5402     | 0.6704    \n",
            "900      | 1.5883       | 0.8849       | 0.7211     | 0.5558     | 0.6715    \n",
            "1000     | 0.9492       | 0.9144       | 0.7075     | 0.5651     | 0.6648    \n",
            "1100     | 1.8102       | 0.8982       | 0.6990     | 0.5656     | 0.6590    \n",
            "-- Avvio Evaluation --\n",
            "1100     | 1.8102       | 0.8101       | 0.7415     | 0.5488     | 0.6837    \n",
            "Accuracy within std: 0.7414965986394558\n",
            "Spearman: 0.5488424824231534\n",
            "Model saved to outputs/models/flan_t5_lora_v1\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33myoung-serenity-70\u001b[0m at: \u001b[34mhttps://wandb.ai/s346291-politecnico-di-torino/huggingface/runs/8ket5q1o\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260128_161538-8ket5q1o/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -u scripts/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "IKOWLDxVAPAD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKOWLDxVAPAD",
        "outputId": "4468b41a-9de0-42b9-a3bf-94ef657bb15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coping model to /content/drive/MyDrive/LLM - Progetto/modelli salvati/versioni/flan-T5-EncDec/flan_lora_20260128_1641...\n",
            "Backup completato! Ora sei al sicuro.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import datetime\n",
        "\n",
        "dest_folder = f\"/content/drive/MyDrive/LLM - Progetto/modelli salvati/versioni/flan-T5-EncDec/flan_lora_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "\n",
        "print(f\"Coping model to {dest_folder}...\")\n",
        "shutil.copytree(\"outputs/models/flan_t5_lora_v1\", dest_folder)\n",
        "print(\"Backup completato! Ora sei al sicuro.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "VvSvPJsLDWh1",
      "metadata": {
        "id": "VvSvPJsLDWh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97758114-b96e-41ed-d95a-6b953b43a559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-28 16:41:13.694720: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-28 16:41:13.712617: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769618473.733665    8019 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769618473.740131    8019 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769618473.757378    8019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769618473.757409    8019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769618473.757419    8019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769618473.757425    8019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-28 16:41:13.763543: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading base model: google/flan-t5-large...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading LoRA adapters from: outputs/models/flan_t5_lora_v1...\n",
            "Leggo i dati da data/raw/test.json...\n",
            "Avvio inferenza su 930 esempi...\n",
            "Predizioni salvate in: outputs/predictions/predictions.jsonl\n",
            "Creo archivio ZIP...\n",
            "Tutto pronto! File da sottomettere: outputs/predictions/predictions.zip\n"
          ]
        }
      ],
      "source": [
        "!python scripts/predict.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "folders_to_download = [\n",
        "    \"/content/code/outputs/models/flan_t5_lora\",\n",
        "    \"/content/code/outputs/models/flan_t5_lora_v1\"\n",
        "]\n",
        "\n",
        "for folder_path in folders_to_download:\n",
        "    if os.path.exists(folder_path):\n",
        "        zip_filename = folder_path.split('/')[-1]\n",
        "\n",
        "        print(f\"Creazione archivio per: {folder_path}...\")\n",
        "        shutil.make_archive(zip_filename, 'zip', folder_path)\n",
        "    else:\n",
        "        print(f\"ERRORE: La cartella {folder_path} non esiste. Controlla il percorso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BGjVtnyNEx1",
        "outputId": "9e8055a7-9221-4ca7-996c-edf657ebf1de"
      },
      "id": "8BGjVtnyNEx1",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creazione archivio per: /content/code/outputs/models/flan_t5_lora...\n",
            "Creazione archivio per: /content/code/outputs/models/flan_t5_lora_v1...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}